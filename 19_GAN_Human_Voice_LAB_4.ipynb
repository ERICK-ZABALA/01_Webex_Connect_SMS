{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1VXEaCr1uM7MAXpqkahEWww556Zurt57d",
      "authorship_tag": "ABX9TyO1iKJBx5SGKa+/OdlQLb+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ERICK-ZABALA/01_Webex_Connect_SMS/blob/main/19_GAN_Human_Voice_LAB_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy tensorflow progressbar2 librosa pyworld\n",
        "\n",
        "!git clone https://github.com/onejiin/CycleGAN-VC2.git\n",
        "!cd CycleGAN-VC2 && python download.py --download_dir ./download --data_dir ./data --datasets vcc2016\n",
        "!apt install ffmpeg\n"
      ],
      "metadata": {
        "id": "4seFcrdb8gPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a43150c-6027-4ee3-ee7e-5b8add61c95a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: progressbar2 in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Collecting pyworld\n",
            "  Using cached pyworld-0.3.4.tar.gz (251 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2) (3.8.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: cython>=0.24 in /usr/local/lib/python3.10/dist-packages (from pyworld) (3.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Building wheels for collected packages: pyworld\n",
            "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.4-cp310-cp310-linux_x86_64.whl size=865273 sha256=59161daacf58ee0dd3bad40d95b3e4dcef270d2735a8a63b1eb4269b9381fd57\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/09/8a/a1d79b73d59756f66e9bfe55a199840efc7473adb76ddacdfd\n",
            "Successfully built pyworld\n",
            "Installing collected packages: tensorflow-estimator, numpy, keras, pyworld, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 numpy-1.26.2 pyworld-0.3.4 tensorboard-2.15.1 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0\n",
            "fatal: destination path 'CycleGAN-VC2' already exists and is not an empty directory.\n",
            "Found: vcc2016_training.zip\n",
            "The size of the file: 0\n",
            "Extracting zip file: vcc2016_training.zip\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CycleGAN-VC2/download.py\", line 93, in <module>\n",
            "    download_vcc2016(download_dir = download_dir, data_dir = data_dir)\n",
            "  File \"/content/CycleGAN-VC2/download.py\", line 70, in download_vcc2016\n",
            "    maybe_unzip(zip_filepath = dataset_filepath, destination_dir = destination_dir, force = False)\n",
            "  File \"/content/CycleGAN-VC2/download.py\", line 56, in maybe_unzip\n",
            "    with zipfile.ZipFile(zip_filepath) as zf:\n",
            "  File \"/usr/lib/python3.10/zipfile.py\", line 1269, in __init__\n",
            "    self._RealGetContents()\n",
            "  File \"/usr/lib/python3.10/zipfile.py\", line 1336, in _RealGetContents\n",
            "    raise BadZipFile(\"File is not a zip file\")\n",
            "zipfile.BadZipFile: File is not a zip file\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd CycleGAN-VC2 && python download.py --help\n"
      ],
      "metadata": {
        "id": "tg-evpKM4tXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d8ac70-f53b-45b8-daa4-6bba9255fb5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: download.py [-h] [--download_dir DOWNLOAD_DIR] [--data_dir DATA_DIR] [--datasets DATASETS]\n",
            "\n",
            "Download CycleGAN voice conversion datasets.\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --download_dir DOWNLOAD_DIR\n",
            "                        Download directory for zipped data\n",
            "  --data_dir DATA_DIR   Data directory for unzipped data\n",
            "  --datasets DATASETS   Datasets available: vcc2016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ],
      "metadata": {
        "id": "pq6tw6Gp5sjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd CycleGAN-VC2 && python train.py --help\n",
        "\n"
      ],
      "metadata": {
        "id": "RI7XY2br5unH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2633b65b-4371-4ad6-9d70-c680157cd8c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-12 05:58:44.040078: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-12-12 05:58:44.273889: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-12 05:58:44.278191: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-12 05:58:44.280294: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-12 05:58:44.334645: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-12-12 05:58:44.335007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-12 05:58:48.752681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "usage: train.py [-h] [--train_A_dir TRAIN_A_DIR] [--train_B_dir TRAIN_B_DIR]\n",
            "                [--model_dir MODEL_DIR] [--model_name MODEL_NAME] [--random_seed RANDOM_SEED]\n",
            "                [--validation_A_dir VALIDATION_A_DIR] [--validation_B_dir VALIDATION_B_DIR]\n",
            "                [--output_dir OUTPUT_DIR] [--tensorboard_log_dir TENSORBOARD_LOG_DIR]\n",
            "                [--gen_model GEN_MODEL] [--MCEPs_dim MCEPS_DIM] [--hdf5A_path HDF5A_PATH]\n",
            "                [--hdf5B_path HDF5B_PATH] [--lambda_cycle LAMBDA_CYCLE]\n",
            "                [--lambda_identity LAMBDA_IDENTITY]\n",
            "\n",
            "Train CycleGAN-VC2 model\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --train_A_dir TRAIN_A_DIR\n",
            "                        Directory for A.\n",
            "  --train_B_dir TRAIN_B_DIR\n",
            "                        Directory for B.\n",
            "  --model_dir MODEL_DIR\n",
            "                        Directory for saving models.\n",
            "  --model_name MODEL_NAME\n",
            "                        File name for saving model.\n",
            "  --random_seed RANDOM_SEED\n",
            "                        Random seed for model training.\n",
            "  --validation_A_dir VALIDATION_A_DIR\n",
            "                        Convert validation A after each training epoch. If set none, no conversion\n",
            "                        would be done during the training.\n",
            "  --validation_B_dir VALIDATION_B_DIR\n",
            "                        Convert validation B after each training epoch. If set none, no conversion\n",
            "                        would be done during the training.\n",
            "  --output_dir OUTPUT_DIR\n",
            "                        Output directory for converted validation voices.\n",
            "  --tensorboard_log_dir TENSORBOARD_LOG_DIR\n",
            "                        TensorBoard log directory.\n",
            "  --gen_model GEN_MODEL\n",
            "                        generator_gatedcnn / generator_gatedcnn_SAGAN\n",
            "  --MCEPs_dim MCEPS_DIM\n",
            "                        input dimension\n",
            "  --hdf5A_path HDF5A_PATH\n",
            "                        hdf5 A domain folder\n",
            "  --hdf5B_path HDF5B_PATH\n",
            "                        hdf5 B domain folder\n",
            "  --lambda_cycle LAMBDA_CYCLE\n",
            "                        lambda cycle\n",
            "  --lambda_identity LAMBDA_IDENTITY\n",
            "                        lambda identity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd CycleGAN-VC2 && python train.py --gen_model CycleGAN-VC2 --model_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/_CycleGAN_CheckPoint\" --train_A_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/SF1\" --train_B_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/TM1\""
      ],
      "metadata": {
        "id": "821puK_ZQ3Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd CycleGAN-VC2 && python preprocess_training.py --help\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImS1IsaJHvd2",
        "outputId": "653c35f3-20e2-483a-9c1d-8d16ef03ed42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/CycleGAN-VC2/preprocess_training.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! sudo rm -rf CycleGAN-VC2/"
      ],
      "metadata": {
        "id": "B-QawzPxeonE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd CycleGAN-VC2 && python preprocess_training.py --train_A_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/SF1\" --train_B_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/TM1\" --cache_folder ./cache/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1QnxtTxD6CZ",
        "outputId": "0c2aa916-cf73-4b17-e708-a69fde27973c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to prepocess data.......\n",
            "Log Pitch A\n",
            "Mean: 5.3331, Std: 0.2483\n",
            "Log Pitch B\n",
            "Mean: 4.7997, Std: 0.1831\n",
            "Preprocessing finsihed!! see your directory ../cache for cached preprocessed data\n",
            "Time taken for preprocessing 17.2045 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd && ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMktwU87ouYu",
        "outputId": "495c8b19-26a1-451d-bce6-942f59b9978d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "CycleGAN-VC2  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd CycleGAN-VC2 && python train.py --logf0s_normalization \"/content/CycleGAN-VC2/cache/logf0s_normalization.npz\" --mcep_normalization \"/content/CycleGAN-VC2/cache/mcep_normalization.npz\" --coded_sps_A_norm \"/content/CycleGAN-VC2/cache/coded_sps_A_norm.pickle\" --coded_sps_B_norm \"/content/CycleGAN-VC2/cache/coded_sps_B_norm.pickle\" --resume_training_at \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/_CycleGAN_CheckPoint.ckpt\" --validation_A_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/evaluation_all/SF1\" --output_A_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/converted_sound/SF1\" --validation_B_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/evaluation_all/TM1\" --output_B_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/converted_sound/TM1/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMA7BMCqSsYw",
        "outputId": "6bf35a86-701e-4f5f-941e-6b5f1bfb10b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/CycleGAN-VC2/train.py\", line 474, in <module>\n",
            "    cycleGAN = CycleGANTraining(logf0s_normalization=logf0s_normalization,\n",
            "  File \"/content/CycleGAN-VC2/train.py\", line 95, in __init__\n",
            "    self.start_epoch = self.loadModel(restart_training_at)\n",
            "  File \"/content/CycleGAN-VC2/train.py\", line 397, in loadModel\n",
            "    self.generator_A2B.load_state_dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for Generator:\n",
            "\tMissing key(s) in state_dict: \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"upSample1.convLayer.0.weight\", \"upSample1.convLayer.0.bias\", \"upSample1.convLayer.2.weight\", \"upSample1.convLayer.2.bias\", \"upSample1.convLayer_gates.0.weight\", \"upSample1.convLayer_gates.0.bias\", \"upSample1.convLayer_gates.2.weight\", \"upSample1.convLayer_gates.2.bias\", \"upSample2.convLayer.0.weight\", \"upSample2.convLayer.0.bias\", \"upSample2.convLayer.2.weight\", \"upSample2.convLayer.2.bias\", \"upSample2.convLayer_gates.0.weight\", \"upSample2.convLayer_gates.0.bias\", \"upSample2.convLayer_gates.2.weight\", \"upSample2.convLayer_gates.2.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"conv2dto1dLayer.0.weight\", \"conv2dto1dLayer.0.bias\", \"conv2dto1dLayer.1.weight\", \"conv2dto1dLayer.1.bias\", \"conv1dto2dLayer.0.weight\", \"conv1dto2dLayer.0.bias\", \"conv1dto2dLayer.1.weight\", \"conv1dto2dLayer.1.bias\", \"convLayer.0.weight\", \"convLayer.0.bias\", \"convLayer.2.weight\", \"convLayer.2.bias\", \"upSample1.0.weight\", \"upSample1.0.bias\", \"upSample1.2.weight\", \"upSample1.2.bias\", \"upSample2.0.weight\", \"upSample2.0.bias\", \"upSample2.2.weight\", \"upSample2.2.bias\". \n",
            "\tsize mismatch for downSample2.convLayer.0.weight: copying a param with shape torch.Size([256, 256, 5, 5]) from checkpoint, the shape in current model is torch.Size([512, 256, 5, 5]).\n",
            "\tsize mismatch for downSample2.convLayer.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for downSample2.convLayer.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for downSample2.convLayer.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for downSample2.convLayer_gates.0.weight: copying a param with shape torch.Size([256, 256, 5, 5]) from checkpoint, the shape in current model is torch.Size([512, 256, 5, 5]).\n",
            "\tsize mismatch for downSample2.convLayer_gates.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for downSample2.convLayer_gates.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for downSample2.convLayer_gates.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer1.conv1d_layer.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer1.conv1d_layer.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer1.conv1d_layer.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer1.conv1d_layer.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer1.conv_layer_gates.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer1.conv_layer_gates.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer1.conv_layer_gates.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer1.conv_layer_gates.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer1.conv1d_out_layer.0.weight: copying a param with shape torch.Size([256, 512, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3]).\n",
            "\tsize mismatch for residualLayer1.conv1d_out_layer.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer1.conv1d_out_layer.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer1.conv1d_out_layer.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer2.conv1d_layer.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer2.conv1d_layer.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer2.conv1d_layer.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer2.conv1d_layer.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer2.conv_layer_gates.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer2.conv_layer_gates.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer2.conv_layer_gates.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer2.conv_layer_gates.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer2.conv1d_out_layer.0.weight: copying a param with shape torch.Size([256, 512, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3]).\n",
            "\tsize mismatch for residualLayer2.conv1d_out_layer.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer2.conv1d_out_layer.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer2.conv1d_out_layer.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer3.conv1d_layer.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer3.conv1d_layer.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer3.conv1d_layer.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer3.conv1d_layer.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer3.conv_layer_gates.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer3.conv_layer_gates.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer3.conv_layer_gates.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer3.conv_layer_gates.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer3.conv1d_out_layer.0.weight: copying a param with shape torch.Size([256, 512, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3]).\n",
            "\tsize mismatch for residualLayer3.conv1d_out_layer.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer3.conv1d_out_layer.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer3.conv1d_out_layer.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer4.conv1d_layer.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer4.conv1d_layer.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer4.conv1d_layer.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer4.conv1d_layer.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer4.conv_layer_gates.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer4.conv_layer_gates.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer4.conv_layer_gates.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer4.conv_layer_gates.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer4.conv1d_out_layer.0.weight: copying a param with shape torch.Size([256, 512, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3]).\n",
            "\tsize mismatch for residualLayer4.conv1d_out_layer.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer4.conv1d_out_layer.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer4.conv1d_out_layer.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer5.conv1d_layer.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer5.conv1d_layer.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer5.conv1d_layer.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer5.conv1d_layer.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer5.conv_layer_gates.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer5.conv_layer_gates.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer5.conv_layer_gates.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer5.conv_layer_gates.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer5.conv1d_out_layer.0.weight: copying a param with shape torch.Size([256, 512, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3]).\n",
            "\tsize mismatch for residualLayer5.conv1d_out_layer.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer5.conv1d_out_layer.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer5.conv1d_out_layer.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer6.conv1d_layer.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer6.conv1d_layer.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer6.conv1d_layer.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer6.conv1d_layer.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer6.conv_layer_gates.0.weight: copying a param with shape torch.Size([512, 256, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3]).\n",
            "\tsize mismatch for residualLayer6.conv_layer_gates.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer6.conv_layer_gates.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer6.conv_layer_gates.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for residualLayer6.conv1d_out_layer.0.weight: copying a param with shape torch.Size([256, 512, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3]).\n",
            "\tsize mismatch for residualLayer6.conv1d_out_layer.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer6.conv1d_out_layer.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for residualLayer6.conv1d_out_layer.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for lastConvLayer.weight: copying a param with shape torch.Size([1, 128, 5, 15]) from checkpoint, the shape in current model is torch.Size([1, 512, 5, 15]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Script para construir la imagen de Docker\n",
        "!docker build --rm -t tensorflow-cyclegan-vc:1.0 -f Dockerfile .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzGyEvP9sEK_",
        "outputId": "5898db80-55b5-4a56-a72a-2a1436a7447f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: docker: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update -y && sudo apt install apt-transport-https ca-certificates curl software-properties-common -y\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnrVPspdtIuD",
        "outputId": "52958919-3999-4a20-9b4f-368c59525646"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,306 kB]\n",
            "Hit:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,036 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,547 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [28.5 kB]\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,578 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,304 kB]\n",
            "Fetched 7,159 kB in 3s (2,472 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "23 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20230311ubuntu0.22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.15).\n",
            "software-properties-common is already the newest version (0.99.22.8).\n",
            "The following NEW packages will be installed:\n",
            "  apt-transport-https\n",
            "0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 1,510 B of archives.\n",
            "After this operation, 170 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 apt-transport-https all 2.4.11 [1,510 B]\n",
            "Fetched 1,510 B in 2s (687 B/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package apt-transport-https.\n",
            "(Reading database ... 120903 files and directories currently installed.)\n",
            "Preparing to unpack .../apt-transport-https_2.4.11_all.deb ...\n",
            "Unpacking apt-transport-https (2.4.11) ...\n",
            "Setting up apt-transport-https (2.4.11) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n"
      ],
      "metadata": {
        "id": "EDvk_b0htT08"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n"
      ],
      "metadata": {
        "id": "MwS51cyHtgYD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHZ813mLtk7D",
        "outputId": "5e82a10c-d93d-49a7-9526-7b599660c7a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\u001b[0m\r                                                                               \rGet:2 https://download.docker.com/linux/ubuntu jammy InRelease [48.8 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Get:5 https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages [26.8 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 75.6 kB in 1s (70.4 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "23 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install docker-ce docker-ce-cli containerd.io\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-snsdJaZttN3",
        "outputId": "4108dedf-31bd-45a8-8446-a3d922c8d8d2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor docker-buildx-plugin docker-ce-rootless-extras\n",
            "  docker-compose-plugin iptables libip6tc2 libnetfilter-conntrack3\n",
            "  libnfnetlink0 libnftnl11 libslirp0 netbase pigz slirp4netns\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils aufs-tools cgroupfs-mount\n",
            "  | cgroup-lite firewalld nftables\n",
            "The following NEW packages will be installed:\n",
            "  apparmor containerd.io docker-buildx-plugin docker-ce docker-ce-cli\n",
            "  docker-ce-rootless-extras docker-compose-plugin iptables libip6tc2\n",
            "  libnetfilter-conntrack3 libnfnetlink0 libnftnl11 libslirp0 netbase pigz\n",
            "  slirp4netns\n",
            "0 upgraded, 16 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 116 MB of archives.\n",
            "After this operation, 417 MB of additional disk space will be used.\n",
            "Get:1 https://download.docker.com/linux/ubuntu jammy/stable amd64 containerd.io amd64 1.6.26-1 [29.5 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pigz amd64 2.6-1 [63.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 netbase all 6.3 [12.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.3 [595 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip6tc2 amd64 1.8.7-1ubuntu5.1 [20.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnfnetlink0 amd64 1.0.1-3build3 [14.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnetfilter-conntrack3 amd64 1.0.9-1 [45.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnftnl11 amd64 1.2.1-1build1 [65.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 iptables amd64 1.8.7-1ubuntu5.1 [455 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libslirp0 amd64 4.6.1-1build1 [61.5 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 slirp4netns amd64 1.0.1-2 [28.2 kB]\n",
            "Get:12 https://download.docker.com/linux/ubuntu jammy/stable amd64 docker-buildx-plugin amd64 0.11.2-1~ubuntu.22.04~jammy [28.2 MB]\n",
            "Get:13 https://download.docker.com/linux/ubuntu jammy/stable amd64 docker-ce-cli amd64 5:24.0.7-1~ubuntu.22.04~jammy [13.3 MB]\n",
            "Get:14 https://download.docker.com/linux/ubuntu jammy/stable amd64 docker-ce amd64 5:24.0.7-1~ubuntu.22.04~jammy [22.6 MB]\n",
            "Get:15 https://download.docker.com/linux/ubuntu jammy/stable amd64 docker-ce-rootless-extras amd64 5:24.0.7-1~ubuntu.22.04~jammy [9,030 kB]\n",
            "Get:16 https://download.docker.com/linux/ubuntu jammy/stable amd64 docker-compose-plugin amd64 2.21.0-1~ubuntu.22.04~jammy [11.9 MB]\n",
            "Fetched 116 MB in 2s (48.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 16.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pigz.\n",
            "(Reading database ... 120907 files and directories currently installed.)\n",
            "Preparing to unpack .../00-pigz_2.6-1_amd64.deb ...\n",
            "Unpacking pigz (2.6-1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../01-netbase_6.3_all.deb ...\n",
            "Unpacking netbase (6.3) ...\n",
            "Selecting previously unselected package apparmor.\n",
            "Preparing to unpack .../02-apparmor_3.0.4-2ubuntu2.3_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.3) ...\n",
            "Selecting previously unselected package libip6tc2:amd64.\n",
            "Preparing to unpack .../03-libip6tc2_1.8.7-1ubuntu5.1_amd64.deb ...\n",
            "Unpacking libip6tc2:amd64 (1.8.7-1ubuntu5.1) ...\n",
            "Selecting previously unselected package libnfnetlink0:amd64.\n",
            "Preparing to unpack .../04-libnfnetlink0_1.0.1-3build3_amd64.deb ...\n",
            "Unpacking libnfnetlink0:amd64 (1.0.1-3build3) ...\n",
            "Selecting previously unselected package libnetfilter-conntrack3:amd64.\n",
            "Preparing to unpack .../05-libnetfilter-conntrack3_1.0.9-1_amd64.deb ...\n",
            "Unpacking libnetfilter-conntrack3:amd64 (1.0.9-1) ...\n",
            "Selecting previously unselected package libnftnl11:amd64.\n",
            "Preparing to unpack .../06-libnftnl11_1.2.1-1build1_amd64.deb ...\n",
            "Unpacking libnftnl11:amd64 (1.2.1-1build1) ...\n",
            "Selecting previously unselected package iptables.\n",
            "Preparing to unpack .../07-iptables_1.8.7-1ubuntu5.1_amd64.deb ...\n",
            "Unpacking iptables (1.8.7-1ubuntu5.1) ...\n",
            "Selecting previously unselected package containerd.io.\n",
            "Preparing to unpack .../08-containerd.io_1.6.26-1_amd64.deb ...\n",
            "Unpacking containerd.io (1.6.26-1) ...\n",
            "Selecting previously unselected package docker-buildx-plugin.\n",
            "Preparing to unpack .../09-docker-buildx-plugin_0.11.2-1~ubuntu.22.04~jammy_amd64.deb ...\n",
            "Unpacking docker-buildx-plugin (0.11.2-1~ubuntu.22.04~jammy) ...\n",
            "Selecting previously unselected package docker-ce-cli.\n",
            "Preparing to unpack .../10-docker-ce-cli_5%3a24.0.7-1~ubuntu.22.04~jammy_amd64.deb ...\n",
            "Unpacking docker-ce-cli (5:24.0.7-1~ubuntu.22.04~jammy) ...\n",
            "Selecting previously unselected package docker-ce.\n",
            "Preparing to unpack .../11-docker-ce_5%3a24.0.7-1~ubuntu.22.04~jammy_amd64.deb ...\n",
            "Unpacking docker-ce (5:24.0.7-1~ubuntu.22.04~jammy) ...\n",
            "Selecting previously unselected package docker-ce-rootless-extras.\n",
            "Preparing to unpack .../12-docker-ce-rootless-extras_5%3a24.0.7-1~ubuntu.22.04~jammy_amd64.deb ...\n",
            "Unpacking docker-ce-rootless-extras (5:24.0.7-1~ubuntu.22.04~jammy) ...\n",
            "Selecting previously unselected package docker-compose-plugin.\n",
            "Preparing to unpack .../13-docker-compose-plugin_2.21.0-1~ubuntu.22.04~jammy_amd64.deb ...\n",
            "Unpacking docker-compose-plugin (2.21.0-1~ubuntu.22.04~jammy) ...\n",
            "Selecting previously unselected package libslirp0:amd64.\n",
            "Preparing to unpack .../14-libslirp0_4.6.1-1build1_amd64.deb ...\n",
            "Unpacking libslirp0:amd64 (4.6.1-1build1) ...\n",
            "Selecting previously unselected package slirp4netns.\n",
            "Preparing to unpack .../15-slirp4netns_1.0.1-2_amd64.deb ...\n",
            "Unpacking slirp4netns (1.0.1-2) ...\n",
            "Setting up libip6tc2:amd64 (1.8.7-1ubuntu5.1) ...\n",
            "Setting up libnftnl11:amd64 (1.2.1-1build1) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up docker-buildx-plugin (0.11.2-1~ubuntu.22.04~jammy) ...\n",
            "Setting up containerd.io (1.6.26-1) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/containerd.service → /lib/systemd/system/containerd.service.\n",
            "Setting up docker-compose-plugin (2.21.0-1~ubuntu.22.04~jammy) ...\n",
            "Setting up docker-ce-cli (5:24.0.7-1~ubuntu.22.04~jammy) ...\n",
            "Setting up libslirp0:amd64 (4.6.1-1build1) ...\n",
            "Setting up pigz (2.6-1) ...\n",
            "Setting up libnfnetlink0:amd64 (1.0.1-3build3) ...\n",
            "Setting up netbase (6.3) ...\n",
            "Setting up docker-ce-rootless-extras (5:24.0.7-1~ubuntu.22.04~jammy) ...\n",
            "Setting up slirp4netns (1.0.1-2) ...\n",
            "Setting up libnetfilter-conntrack3:amd64 (1.0.9-1) ...\n",
            "Setting up iptables (1.8.7-1ubuntu5.1) ...\n",
            "update-alternatives: using /usr/sbin/iptables-legacy to provide /usr/sbin/iptables (iptables) in auto mode\n",
            "update-alternatives: using /usr/sbin/ip6tables-legacy to provide /usr/sbin/ip6tables (ip6tables) in auto mode\n",
            "update-alternatives: using /usr/sbin/iptables-nft to provide /usr/sbin/iptables (iptables) in auto mode\n",
            "update-alternatives: using /usr/sbin/ip6tables-nft to provide /usr/sbin/ip6tables (ip6tables) in auto mode\n",
            "update-alternatives: using /usr/sbin/arptables-nft to provide /usr/sbin/arptables (arptables) in auto mode\n",
            "update-alternatives: using /usr/sbin/ebtables-nft to provide /usr/sbin/ebtables (ebtables) in auto mode\n",
            "Setting up docker-ce (5:24.0.7-1~ubuntu.22.04~jammy) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /lib/systemd/system/docker.service.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/docker.socket → /lib/systemd/system/docker.socket.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo adduser ezabala\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NMzrytvupzJ",
        "outputId": "613f9e82-a4f7-4807-e0da-0f1c03af5ca9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding user `ezabala' ...\n",
            "Adding new group `ezabala' (1000) ...\n",
            "Adding new user `ezabala' (1000) with group `ezabala' ...\n",
            "Creating home directory `/home/ezabala' ...\n",
            "Copying files from `/etc/skel' ...\n",
            "New password: \n",
            "Retype new password: \n",
            "passwd: password updated successfully\n",
            "Changing the user information for ezabala\n",
            "Enter the new value, or press ENTER for the default\n",
            "\tFull Name []: erick\n",
            "\tRoom Number []: 6273\n",
            "\tWork Phone []: \n",
            "\tHome Phone []: \n",
            "\tOther []: \n",
            "Is the information correct? [Y/n] y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo usermod -aG docker ezabala"
      ],
      "metadata": {
        "id": "07KdIOdZuYFs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!id ezabala\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkn-eP0VvFeR",
        "outputId": "2dc55bc6-8697-45d1-cc37-98d5b63f18c5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uid=1000(ezabala) gid=1000(ezabala) groups=1000(ezabala),999(docker)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!docker --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMQdNUwbvMK_",
        "outputId": "4a71afe2-f452-4ae8-a36a-78e8bfe6a735"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Docker version 24.0.7, build afdd53b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo service docker status\n",
        "!sudo service docker start\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhD9_vwpvudy",
        "outputId": "b4fa9b04-7944-455d-dee4-99303d481547"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Docker is not running\n",
            " * Starting Docker: docker\n",
            "   ...done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo service docker status && sudo service docker start\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXnoWevav33J",
        "outputId": "25ba5beb-969a-437d-df92-43ddc85ac7d7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Docker is not running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo docker build --rm -t tensorflow-cyclegan-vc:1.0 -f Dockerfile ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9Kqjj0IvRxv",
        "outputId": "c0891697-7f86-4671-8c42-b4f8f5661ae0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "twoC8kgNEHPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd CycleGAN-VC2 && python test.py --logf0s_normalization \"/content/CycleGAN-VC2/cache/logf0s_normalization.npz\" --mcep_normalization \"/content/CycleGAN-VC2/cache/mcep_normalization.npz\" --test_A_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/evaluation_all/SF1\" --output_A_dir \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/convert/SF1\" --model_checkpoint \"/content/drive/MyDrive/Colab Notebooks/GAN/vcc2016_training/_CycleGAN_CheckPoint\""
      ],
      "metadata": {
        "id": "PsAYxqnCNJbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A01Rb6k-EG2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd CycleGAN-VC2 && python train.py --gen_model CycleGAN-VC2"
      ],
      "metadata": {
        "id": "moM9NcFG9Xq-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}